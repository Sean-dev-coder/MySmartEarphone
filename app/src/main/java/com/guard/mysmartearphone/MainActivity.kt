package com.guard.mysmartearphone

import android.media.AudioDeviceInfo
import android.media.AudioManager
import android.content.Intent
import android.os.Bundle
import android.speech.RecognizerIntent
import android.speech.SpeechRecognizer
import android.speech.RecognitionListener
import android.widget.Button
import android.widget.TextView
import android.util.Log // æ‰“å°LOG
import androidx.appcompat.app.AppCompatActivity
import android.speech.tts.TextToSpeech
import java.util.Locale

class MainActivity : AppCompatActivity() {

    private lateinit var speechRecognizer: SpeechRecognizer
    private lateinit var tvResult: TextView
    private lateinit var tts: TextToSpeech    // å®šç¾©ã€Œå˜´å·´ã€

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        setContentView(R.layout.activity_main)
        // åœ¨å•Ÿå‹•ç›£è½çš„åŒæ™‚ï¼Œå•Ÿå‹•å‰æ™¯æœå‹™
        val serviceIntent = Intent(this, VoiceService::class.java)
        startForegroundService(serviceIntent)
        // è«‹æ±‚æ¬Šé™
        requestPermissions(arrayOf(android.Manifest.permission.RECORD_AUDIO), 101)

        val btnListen = findViewById<Button>(R.id.btn_listen)
        val tvStatus = findViewById<TextView>(R.id.tv_source_status)
        tvResult = findViewById<TextView>(R.id.tv_speech_result)

        // åˆå§‹åŒ–èªéŸ³è¾¨è­˜å™¨
        speechRecognizer = SpeechRecognizer.createSpeechRecognizer(this)

        btnListen.setOnClickListener {
            checkAudioSource(tvStatus) // æª¢æŸ¥ä¾†æº
            startListening()           // é–‹å§‹è½èªªè©±
        }

        // åˆå§‹åŒ– TTS
        tts = TextToSpeech(this) { status ->
            if (status == TextToSpeech.SUCCESS) {
                // è¨­å®šèªè¨€ç‚ºå°ç£ä¸­æ–‡
                val result = tts.setLanguage(Locale.TAIWAN)
                if (result == TextToSpeech.LANG_MISSING_DATA || result == TextToSpeech.LANG_NOT_SUPPORTED) {
                    Log.e("TTS", "é€™å°æ‰‹æ©Ÿä¸æ”¯æ´å°ç£ä¸­æ–‡èªéŸ³")
                }
            } else {
                Log.e("TTS", "TTS åˆå§‹åŒ–å¤±æ•—")
            }
        }
    }

    // 1. å®šç¾©ä¸€å€‹è®Šæ•¸ä¾†æ§åˆ¶æ˜¯å¦è¦ç¹¼çºŒè½ï¼ˆåƒæ˜¯é–‹é—œï¼‰
    private var isKeepListening = true

    private fun startListening() {
        isKeepListening = true // æ¯æ¬¡æŒ‰æŒ‰éˆ•å•Ÿå‹•æ™‚ï¼Œç¢ºä¿é–‹é—œæ˜¯æ‰“é–‹çš„

        val intent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
            putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
            putExtra(RecognizerIntent.EXTRA_LANGUAGE, "zh-TW")
        }

        speechRecognizer.setRecognitionListener(object : RecognitionListener {
            override fun onReadyForSpeech(params: Bundle?) {
                // ä¸è¦æ¯æ¬¡éƒ½è¦†è“‹æ‰ tvResultï¼Œæˆ‘å€‘æ”¹ç”¨ã€Œç‹€æ…‹é¡¯ç¤ºã€
                findViewById<TextView>(R.id.tv_source_status).text = "ğŸ™ æ­£åœ¨è½å–ä¸­ï¼ˆèªªã€ŒçµæŸæŸ¥è©¢ã€å¯åœæ­¢ï¼‰"
            }

            override fun onResults(results: Bundle?) {
                val data = results?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                val text = data?.get(0) ?: ""

                // å°‡è¾¨è­˜åˆ°çš„å­—å°åœ¨ç™½æ¡†å€åŸŸ
                tvResult.text = "ä½ èªªï¼š$text"

                // ğŸŒŸ æ ¸å¿ƒé‚è¼¯ï¼šæª¢æŸ¥é—œéµå­—
                if (text.contains("çµæŸæŸ¥è©¢") || text.contains("åœæ­¢") || text.contains("çµæŸ")) {
                    tvResult.append("\nâœ… å·²æ”¶åˆ°åœæ­¢æŒ‡ä»¤ã€‚")
                    isKeepListening = false // é—œé–‰é–‹é—œ
                    speakOut("å¥½çš„ï¼Œå·²ç‚ºæ‚¨çµæŸæŸ¥è©¢æœå‹™ã€‚")
                    speechRecognizer.stopListening()
                } else {
                    // å¦‚æœä¸æ˜¯åœæ­¢æŒ‡ä»¤ï¼Œç¨å¾®ç­‰ 0.5 ç§’å¾Œå†æ¬¡å•Ÿå‹•ï¼Œé¿å…ç³»çµ±å¤ªç´¯
                    if (isKeepListening) {
                        android.os.Handler(android.os.Looper.getMainLooper()).postDelayed({
                            startListening()
                        }, 500)
                    }
                    speakOut("æ‚¨å‰›å‰›èªªçš„æ˜¯ï¼š$text")
                }
            }
            override fun onError(error: Int) {
                // ç•¶å› ç‚ºã€Œå¤ªä¹…æ²’èªªè©±ã€å°è‡´è‡ªå‹•ä¸­æ–· (Error 7) æ™‚ï¼Œè‡ªå‹•é‡å•Ÿ
                if (isKeepListening) {
                    startListening()
                } else {
                    findViewById<TextView>(R.id.tv_source_status).text = "ğŸ›‘ éŒ„éŸ³å·²åœæ­¢"
                }
            }
            override fun onBeginningOfSpeech() {}
            override fun onRmsChanged(rmsdB: Float) {}
            override fun onBufferReceived(buffer: ByteArray?) {}
            override fun onEndOfSpeech() {}
            override fun onPartialResults(partialResults: Bundle?) {}
            override fun onEvent(eventType: Int, params: Bundle?) {}
        })

        speechRecognizer.startListening(intent)
    }

    class MainActivity : AppCompatActivity() {

        private lateinit var speechRecognizer: SpeechRecognizer
        private lateinit var tvResult: TextView

        override fun onCreate(savedInstanceState: Bundle?) {
            super.onCreate(savedInstanceState)
            setContentView(R.layout.activity_main)

            // è«‹æ±‚æ¬Šé™
            requestPermissions(arrayOf(android.Manifest.permission.RECORD_AUDIO), 101)

            val btnListen = findViewById<Button>(R.id.btn_listen)
            val tvStatus = findViewById<TextView>(R.id.tv_source_status)
            tvResult = findViewById<TextView>(R.id.tv_speech_result)

            // åˆå§‹åŒ–èªéŸ³è¾¨è­˜å™¨
            speechRecognizer = SpeechRecognizer.createSpeechRecognizer(this)

            btnListen.setOnClickListener {
                checkAudioSource(tvStatus) // æª¢æŸ¥ä¾†æº
                startListening()           // é–‹å§‹è½èªªè©±
            }
        }

        private fun startListening() {
            val intent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
                putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
                putExtra(RecognizerIntent.EXTRA_LANGUAGE, "zh-TW") // è¨­å®šç‚ºå°ç£ä¸­æ–‡
            }

            speechRecognizer.setRecognitionListener(object : RecognitionListener {
                override fun onReadyForSpeech(params: Bundle?) { tvResult.text = "è«‹é–‹å§‹èªªè©±..." }
                override fun onBeginningOfSpeech() {}
                override fun onRmsChanged(rmsdB: Float) {}
                override fun onBufferReceived(buffer: ByteArray?) {}
                override fun onEndOfSpeech() {}
                override fun onError(error: Int) { tvResult.text = "è¾¨è­˜éŒ¯èª¤ï¼š$error" }

                // é€™æ˜¯æœ€é‡è¦çš„éƒ¨åˆ†ï¼šå¾—åˆ°çµæœ
                override fun onResults(results: Bundle?) {
                    val data = results?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                    tvResult.text = data?.get(0) ?: "è½ä¸æ¸…æ¥šï¼Œè«‹å†èªªä¸€æ¬¡"
                }

                override fun onPartialResults(partialResults: Bundle?) {}
                override fun onEvent(eventType: Int, params: Bundle?) {}
            })

            speechRecognizer.startListening(intent)
        }

        // åˆ¤æ–·è²éŸ³ä¾†æºçš„å°ˆå®¶ç´šå‡½å¼
        private fun checkAudioSource(statusView: TextView) {
            val audioManager = getSystemService(AUDIO_SERVICE) as AudioManager
            val devices = audioManager.getDevices(AudioManager.GET_DEVICES_INPUTS)

            var sourceName = "æ‰‹æ©Ÿå…§å»ºéº¥å…‹é¢¨"

            for (device in devices) {
                // åˆ¤æ–·æ˜¯å¦ç‚ºè—ç‰™è€³æ©Ÿé€šè¨Šæ ¼å¼ (SCO)
                if (device.type == AudioDeviceInfo.TYPE_BLUETOOTH_SCO ||
                    device.type == AudioDeviceInfo.TYPE_BLUETOOTH_A2DP) {
                    sourceName = "JLab è—ç‰™è€³æ©Ÿ (å·²é€£ç·š)"
                    break
                }
            }

            statusView.text = "ç›®å‰æ”¶éŸ³è·¯å¾‘ï¼š$sourceName"
        }
    }

    // åˆ¤æ–·è²éŸ³ä¾†æºçš„å°ˆå®¶ç´šå‡½å¼
    private fun checkAudioSource(statusView: TextView) {
        val audioManager = getSystemService(AUDIO_SERVICE) as AudioManager
        val devices = audioManager.getDevices(AudioManager.GET_DEVICES_INPUTS)

        var sourceName = "æ‰‹æ©Ÿå…§å»ºéº¥å…‹é¢¨"

        for (device in devices) {
            // åˆ¤æ–·æ˜¯å¦ç‚ºè—ç‰™è€³æ©Ÿé€šè¨Šæ ¼å¼ (SCO)
            if (device.type == AudioDeviceInfo.TYPE_BLUETOOTH_SCO ||
                device.type == AudioDeviceInfo.TYPE_BLUETOOTH_A2DP) {
                sourceName = "JLab è—ç‰™è€³æ©Ÿ (å·²é€£ç·š)"
                break
            }
        }
        statusView.text = "ç›®å‰æ”¶éŸ³è·¯å¾‘ï¼š$sourceName"
    }

    private fun speakOut(text: String) {
        // è®“ App æŠŠè©±å”¸å‡ºä¾†
        // QUEUE_FLUSH ä»£è¡¨ï¼šå¦‚æœç¾åœ¨æ­£åœ¨å”¸åˆ¥çš„ï¼Œå°±æŠŠå®ƒä¸­æ–·ï¼Œæ”¹å”¸é€™å¥æ–°çš„
        tts.speak(text, TextToSpeech.QUEUE_FLUSH, null, "UtteranceID")

        // å°ˆå®¶ç´šé‚è¼¯ï¼šç›£æ¸¬ä»€éº¼æ™‚å€™ã€Œå”¸å®Œäº†ã€ï¼Œå”¸å®Œå†é‡æ–°å•Ÿå‹•éŒ„éŸ³ï¼Œé¿å…ã€Œè‡ªè¨€è‡ªèªã€
        tts.setOnUtteranceProgressListener(object : android.speech.tts.UtteranceProgressListener() {
            override fun onStart(utteranceId: String?) {}
            override fun onDone(utteranceId: String?) {
                // ç•¶ App å”¸å®Œè³‡æ–™å¾Œï¼Œè‡ªå‹•å•Ÿå‹•ä¸‹ä¸€è¼ªç›£è½
                runOnUiThread {
                    if (isKeepListening) {
                        startListening()
                    }
                }
            }
            override fun onError(utteranceId: String?) {}
        })
    }

    // ç•¶é€™å€‹ Activity (ç•«é¢) è¢«éŠ·æ¯€æ™‚æœƒåŸ·è¡Œé€™è£¡
    override fun onDestroy() {
        // 1. å…ˆåœæ­¢èªªè©±
        if (::tts.isInitialized) {
            tts.stop()
            // 2. é‡‹æ”¾èªéŸ³å¼•æ“è³‡æº
            tts.shutdown()
        }

        // 3. åŒæ™‚ä¹ŸæŠŠèªéŸ³è¾¨è­˜å™¨é—œæ‰ï¼Œçœé›»ä¸¦é‡‹æ”¾éº¥å…‹é¢¨
        if (::speechRecognizer.isInitialized) {
            speechRecognizer.destroy()
        }
        Log.d("MY_APP_DEBUG", "destroy")

        super.onDestroy() // é€™è¡Œä¸€å®šè¦åœ¨æœ€å¾Œé¢
    }
}