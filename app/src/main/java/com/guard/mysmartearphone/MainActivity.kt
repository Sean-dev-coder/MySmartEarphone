package com.guard.mysmartearphone
import com.google.firebase.firestore.Source // ğŸŒŸ è¨˜å¾—åŠ é€™è¡Œ import
import com.google.firebase.firestore.ktx.firestore
import com.google.firebase.firestore.DocumentSnapshot
import com.google.firebase.firestore.FirebaseFirestore
import com.google.firebase.firestore.FirebaseFirestoreSettings
import com.google.firebase.firestore.PersistentCacheSettings
import com.google.firebase.ktx.Firebase
import android.media.AudioDeviceInfo
import android.media.AudioManager
import android.content.Intent
import android.os.Bundle
import android.os.Handler
import android.os.Looper
import android.speech.RecognizerIntent
import android.speech.SpeechRecognizer
import android.speech.RecognitionListener
import android.view.View
import android.widget.AdapterView
import android.widget.ArrayAdapter
import android.widget.Spinner
import android.widget.Button
import android.widget.TextView
import android.util.Log
import androidx.appcompat.app.AppCompatActivity
import android.speech.tts.TextToSpeech
import android.speech.tts.UtteranceProgressListener
import java.text.SimpleDateFormat
import java.util.Date
import java.util.Locale

class MainActivity : AppCompatActivity() {

    private lateinit var speechRecognizer: SpeechRecognizer
    private lateinit var tvResult: TextView
    private lateinit var tvDebugLog: TextView
    private lateinit var tts: TextToSpeech
    private var selectedCommunity = "è«‹é¸æ“‡"
    private var isFirstLoad = true
    private var isKeepListening = false
    private var isTtsSpeaking = false
    private var lastQueryDocuments: List<DocumentSnapshot> = listOf()
    private val handler = Handler(Looper.getMainLooper())
    private val communityPathMap = mapOf(
        "å¤§é™¸éº—æ ¼" to "licensePlates",
        "å¤§é™¸è±è’”" to "licensePlates_epoque",
        "å¤§é™¸å¯¶æ ¼" to "licensePlates_treasure"
    )
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        setContentView(R.layout.activity_main)

        // âœ… ä¿®å¾©ï¼šUse property access syntax
        tvResult = findViewById(R.id.tv_speech_result)
        tvDebugLog = findViewById(R.id.tv_debug_log)
        val spinner = findViewById<Spinner>(R.id.spinner_community)
        val btnListen = findViewById<Button>(R.id.btn_listen)
        val tvStatus = findViewById<TextView>(R.id.tv_source_status)

        setupModernAudio()
        setupFirestoreOffline()

        // ğŸŒŸ ç¢ºä¿åˆå§‹åŒæ­¥åƒæ•¸æ­£ç¢º
        syncAllDataForOffline("licensePlates")

        val serviceIntent = Intent(this, VoiceService::class.java)
        startForegroundService(serviceIntent)

        val communities = arrayOf("å¤§é™¸éº—æ ¼", "å¤§é™¸è±è’”", "å¤§é™¸å¯¶æ ¼")
        val adapter = ArrayAdapter(this, android.R.layout.simple_spinner_item, communities)
        adapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item)
        spinner.adapter = adapter

        spinner.onItemSelectedListener = object : AdapterView.OnItemSelectedListener {
            override fun onItemSelected(parent: AdapterView<*>?, view: View?, position: Int, id: Long) {
                selectedCommunity = communities[position]

                // 1. Get the English path from the map (default to licensePlates if not found)
                val collectionPath = communityPathMap[selectedCommunity] ?: "licensePlates"

                if (isFirstLoad) {
                    isFirstLoad = false
                    return
                }

                stopSpeechLogic()
                speakOut("å·²åˆ‡æ›è‡³ $selectedCommunity")

                // 2. Pass the correct English path to sync
                syncAllDataForOffline(collectionPath)

                // 3. Updated log to show both names for debugging
                addLog("ğŸ“ åˆ‡æ›ç¤¾å€: $selectedCommunity (è·¯å¾‘: $collectionPath)")
            }
            override fun onNothingSelected(parent: AdapterView<*>?) {}
        }

        tts = TextToSpeech(this) { status ->
            if (status == TextToSpeech.SUCCESS) {
                tts.setLanguage(Locale.TAIWAN)
                setupTTSListener()
                addLog("ğŸ“¢ TTS èªéŸ³å¼•æ“å°±ç·’")
            }
        }

        speechRecognizer = SpeechRecognizer.createSpeechRecognizer(this)

        btnListen.setOnClickListener {
            checkAudioSource(tvStatus)
            isKeepListening = true
            setupModernAudio()
            startListening()
            addLog("ğŸš€ é–‹å§‹åŸ·å‹¤ç›£è½æ¨¡å¼")
        }
    }

    private fun setupTTSListener() {
        tts.setOnUtteranceProgressListener(object : UtteranceProgressListener() {
            override fun onStart(utteranceId: String?) { isTtsSpeaking = true }
            override fun onDone(utteranceId: String?) {
                isTtsSpeaking = false
                runOnUiThread {
                    if (isKeepListening) {
                        handler.postDelayed({ if (!isTtsSpeaking) startListening() }, 1000)
                    }
                }
            }
            override fun onError(utteranceId: String?) { isTtsSpeaking = false }
        })
    }

    private fun startListening() {
        // 1. æ ¸å¿ƒå®ˆå‰‡ï¼šTTS èªªè©±æ™‚çµ•å°ä¸å‡†å•Ÿå‹•ç›£è½ï¼Œé€™æ˜¯é¿å… Error 11 çš„é—œéµ
        if (isTtsSpeaking) return
        handler.removeCallbacksAndMessages(null)

        // 2. ç¢ºä¿éŸ³è¨Šè·¯å¾‘ (è—ç‰™/è€³æ©Ÿ) é–å®š
        setupModernAudio()

        try {
            // 3. å¦‚æœå¼•æ“æ²’åˆå§‹åŒ–ï¼Œæ‰å»ºç«‹å®ƒ
            if (!::speechRecognizer.isInitialized) {
                speechRecognizer = SpeechRecognizer.createSpeechRecognizer(this)
            } else {
                // ğŸŒŸ æ²»æœ¬é—œéµï¼šä¸è¦ destroyï¼Œè€Œæ˜¯ç”¨ cancel() å¼·åˆ¶å°‡ç‹€æ…‹æ©Ÿæ­¸é›¶
                speechRecognizer.cancel()
            }

            // 4. æ¯æ¬¡å•Ÿå‹•å‰é‡æ–°ç¶å®šç›£è½å™¨ï¼Œç¢ºä¿ Callback éˆæ¢å®Œæ•´
            speechRecognizer.setRecognitionListener(object : RecognitionListener {
                override fun onReadyForSpeech(params: Bundle?) {
                    runOnUiThread { findViewById<TextView>(R.id.tv_source_status).text = "ğŸ™ æ­£åœ¨è½å– $selectedCommunity..." }
                }

                override fun onResults(results: Bundle?) {
                    val data = results?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                    val text = data?.get(0) ?: ""
                    addLog("ğŸ‘‚ è½å–åˆ°: $text")

                    if (text.contains("çµæŸ") || text.contains("åœæ­¢")) {
                        isKeepListening = false
                        resetToNormalAudioMode()
                        lastQueryDocuments = listOf()
                        speakOut("å·²çµæŸæŸ¥è©¢æœå‹™")
                        return
                    }

                    // è™•ç†å¤šç­†é¸æ“‡é‚è¼¯
                    if (lastQueryDocuments.size > 1) {
                        val index = when {
                            text.contains("ç¬¬ä¸€å€‹") || text == "1" || text == "ä¸€" -> 0
                            text.contains("ç¬¬äºŒå€‹") || text == "2" || text == "äºŒ" -> 1
                            text.contains("ç¬¬ä¸‰å€‹") || text == "3" || text == "ä¸‰" -> 2
                            else -> -1
                        }
                        if (index != -1 && index < lastQueryDocuments.size) {
                            val doc = lastQueryDocuments[index]
                            lastQueryDocuments = listOf()
                            processSelection(doc)
                            return
                        }
                    }

                    lastQueryDocuments = listOf()
                    queryVehicle(text)

                    // ğŸ’¡ è¨»ï¼šé€™è£¡ä¸æ‰‹å‹•é‡å•Ÿï¼Œç”± queryVehicle å…§çš„ TTS å®Œæˆå¾Œè§¸ç™¼ startListening
                }

                override fun onError(error: Int) {
                    if (isKeepListening) {
                        val errorMsg = when(error) {
                            11 -> "ç³»çµ±æš«æ™‚é–å®š (11)"
                            SpeechRecognizer.ERROR_NETWORK_TIMEOUT -> "ç¶²è·¯é€¾æ™‚"
                            SpeechRecognizer.ERROR_NETWORK -> "ç¶²è·¯é€£ç·šå¤±æ•—"
                            SpeechRecognizer.ERROR_AUDIO -> "éŸ³è¨ŠéŒ„è£½éŒ¯èª¤ (è«‹æª¢æŸ¥éº¥å…‹é¢¨)"
                            SpeechRecognizer.ERROR_SERVER -> "Google ä¼ºæœå™¨ç•°å¸¸"
                            SpeechRecognizer.ERROR_CLIENT -> "æ‰‹æ©Ÿç«¯é‚è¼¯éŒ¯èª¤"
                            SpeechRecognizer.ERROR_SPEECH_TIMEOUT -> "è½å–è¶…æ™‚ (æ²’äººèªªè©±)" //
                            SpeechRecognizer.ERROR_NO_MATCH -> "æœªè½æ¸…/æ‰¾ä¸åˆ°åŒ¹é…çµæœ"
                            SpeechRecognizer.ERROR_RECOGNIZER_BUSY -> "è¾¨è­˜å¼•æ“å¿™ç¢Œä¸­ (è«‹é‡å•Ÿ)"
                            SpeechRecognizer.ERROR_INSUFFICIENT_PERMISSIONS -> "ç¼ºä¹éŒ„éŸ³æ¬Šé™"
                            SpeechRecognizer.ERROR_TOO_MANY_REQUESTS -> "é€£ç·šè«‹æ±‚éæ–¼é »ç¹"
                            SpeechRecognizer.ERROR_SERVER_DISCONNECTED -> "èˆ‡ä¼ºæœå™¨æ–·é–‹é€£ç·š"
                            SpeechRecognizer.ERROR_LANGUAGE_NOT_SUPPORTED -> "ä¸æ”¯æ´æ­¤èªè¨€"
                            SpeechRecognizer.ERROR_LANGUAGE_UNAVAILABLE -> "èªè¨€åŒ…æš«æ™‚ä¸å¯ç”¨"
                            else -> "éŒ¯èª¤ $error"
                        }
                        addLog("ğŸ”´ $errorMsgï¼Œ1.5ç§’å¾Œè‡ªå‹•é‡è©¦")

                        // å‡ºéŒ¯æ™‚çµ¦ä¸€é»ç·©è¡æ™‚é–“å†é‡å•Ÿï¼Œé¿å…é€²å…¥é€£ç’°å ±éŒ¯
                        handler.postDelayed({
                            if (isKeepListening && !isTtsSpeaking) startListening()
                        }, 1500)
                    }
                }

                // å¿…è¦ç©ºå¯¦ä½œ
                override fun onBeginningOfSpeech() {}
                override fun onRmsChanged(rmsdB: Float) {}
                override fun onBufferReceived(buffer: ByteArray?) {}
                override fun onEndOfSpeech() {}
                override fun onPartialResults(partialResults: Bundle?) {}
                override fun onEvent(eventType: Int, params: Bundle?) {}
            })

            // 5. è¨­å®šå•Ÿå‹•åƒæ•¸
            val intent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
                putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_WEB_SEARCH)
                putExtra(RecognizerIntent.EXTRA_LANGUAGE, "zh-TW")
                // æ¸›å°‘ç³»çµ±è² æ“”ï¼Œåªæ‹¿ä¸€ç­†çµæœ
                putExtra(RecognizerIntent.EXTRA_MAX_RESULTS, 1)
            }

            speechRecognizer.startListening(intent)

        } catch (e: Exception) {
            addLog("âŒ å•Ÿå‹•å¤±æ•—: ${e.message}")
            handler.postDelayed({ if (isKeepListening) startListening() }, 2000)
        }
    }

    private fun queryVehicle(plateText: String) {
        val cleanPlate = convertSpokenPlate(plateText)
        if (cleanPlate.isBlank()) return// Use the mapping logic for consistency
        val collectionPath = communityPathMap[selectedCommunity] ?: "licensePlates"

        val db = Firebase.firestore
        val isOnline = isNetworkAvailable()
        val source = if (isOnline) Source.DEFAULT else Source.CACHE

        addLog("ğŸ” æª¢ç´¢ [$selectedCommunity] -> $cleanPlate (é›†åˆ: $collectionPath, ä¾†æº: ${if(source == Source.CACHE) "é›¢ç·š" else "é›²ç«¯"})")

        db.collection(collectionPath).document(cleanPlate).get(source)
            .addOnSuccessListener { document ->
                if (document != null && document.exists()) {
                    processSingleResult(document, cleanPlate)
                } else {
                    runFuzzyQuery(collectionPath, cleanPlate, source)
                }
            }
            .addOnFailureListener { e ->
                if (source == Source.CACHE && isNetworkAvailable()) {
                    addLog("âš ï¸ æœ¬åœ°ç„¡ç´€éŒ„ï¼Œå˜—è©¦é›²ç«¯...")
                    db.collection(collectionPath).document(cleanPlate).get(Source.SERVER)
                        .addOnSuccessListener { processSingleResult(it, cleanPlate) }
                        .addOnFailureListener { addLog("âŒ é›²ç«¯äº¦ç„¡è³‡æ–™"); speakOut("æŸ¥ç„¡æ­¤è»Š") }
                } else {
                    addLog("âŒ æŸ¥è©¢å¤±æ•—: ${e.message}")
                    speakOut("ç›®å‰é›¢ç·šä¸”æŸ¥ç„¡æœ¬åœ°ç´€éŒ„")
                }
            }
    }
    // ğŸ¥ æ¨¡ç³ŠæŸ¥è©¢å°ˆç”¨å‚™æ´å‡½å¼
    private fun runFuzzyQuery(collectionPath: String, cleanPlate: String, source: Source) {
        val db = Firebase.firestore
        db.collection(collectionPath).whereArrayContains("searchKeywords", cleanPlate).get(source)
            .addOnSuccessListener { documents ->
                handleMultipleResults(documents, cleanPlate)
            }
            .addOnFailureListener { e ->
                // æ¨¡ç³ŠæŸ¥è©¢ä¹ŸåŒæ¨£åšä¸€æ¬¡é›²ç«¯é™ç´šå‚™æ´
                if (source == Source.CACHE && isNetworkAvailable()) {
                    db.collection(collectionPath).whereArrayContains("searchKeywords", cleanPlate).get(Source.SERVER)
                        .addOnSuccessListener { handleMultipleResults(it, cleanPlate) }
                } else {
                    addLog("âŒ æ¨¡ç³ŠæŸ¥è©¢å ±éŒ¯: ${e.message}")
                }
            }
    }

    // ğŸ¥ ç¶²è·¯ç‹€æ…‹æª¢æŸ¥å°å·¥å…· (è«‹ç¢ºä¿é€™æ®µä¹Ÿåœ¨ MainActivity å…§)
    private fun isNetworkAvailable(): Boolean {
        val cm = getSystemService(android.content.Context.CONNECTIVITY_SERVICE) as android.net.ConnectivityManager
        val activeNetwork = cm.activeNetworkInfo
        return activeNetwork != null && activeNetwork.isConnectedOrConnecting
    }
    private fun processSingleResult(document: DocumentSnapshot, plateText: String) {
        val houseCode = document.getString("householdCode") ?: "æœªçŸ¥"
        val notes = document.getString("notes") ?: ""
        val source = if (document.metadata.isFromCache) "æœ¬åœ°" else "é›²ç«¯"
        runOnUiThread {
            tvResult.text = "âœ… æˆåŠŸï¼š$houseCode\nè»Šç‰Œï¼š$plateText\nä¾†æºï¼š$source"
        }
        addLog("âœ… [$source] åŒ¹é…æˆåŠŸ: $houseCode") // ğŸ‘ˆ é€™è£¡æœƒé¡¯ç¤ºä¾†æº
        speakOut("æ‰¾åˆ°äº†ï¼Œé€™æ˜¯ $houseCode çš„ä½æˆ¶ã€‚$notes")
    }
    private fun handleMultipleResults(documents: com.google.firebase.firestore.QuerySnapshot, plateText: String) {
        if (documents.isEmpty) {
            runOnUiThread { tvResult.text = "âŒ æŸ¥ç„¡è³‡æ–™ï¼š$plateText" }
            addLog("â“ ç„¡åŒ¹é…ç´€éŒ„")
            speakOut("æ‰¾ä¸åˆ°è»Šç‰Œ $plateText çš„è³‡æ–™")
            return
        }
        val source = if (documents.metadata.isFromCache) "æœ¬åœ°" else "é›²ç«¯"
        lastQueryDocuments = documents.documents
        if (documents.size() == 1) {
            val doc = documents.documents[0]
            val hCode = doc.getString("householdCode") ?: ""
            runOnUiThread { tvResult.text = "ğŸ” æ¨¡ç³Šå‘½ä¸­ï¼š$hCode\nè»Šç‰Œï¼š${doc.id}" }
            addLog("âœ… [$source] æ¨¡ç³Šæ¯”å°æˆåŠŸ: $hCode")
            speakOut("æŸ¥åˆ°äº†ï¼Œé€™æ˜¯ $hCode çš„è»Š")
        } else {
            val total = documents.size()
            addLog("âš ï¸ [$source] ç™¼ç¾ ${documents.size()} ç­†ç›¸ä¼¼è³‡æ–™")
            val houseList = documents.documents.take(3).mapIndexed { i, d ->
                "ç¬¬${i + 1}å€‹${d.getString("householdCode") ?: "æœªçŸ¥"}"
            }.joinToString(" ")
            speakOut("æ‰¾åˆ° $total ç­†é‡å° $plateText çš„çµæœï¼Œè«‹å•é¸ç¬¬å¹¾å€‹ï¼Ÿ $houseList")
        }
    }

    private fun speakOut(text: String) {
        isTtsSpeaking = true
        speechRecognizer.stopListening()
        val params = Bundle().apply { putString(TextToSpeech.Engine.KEY_PARAM_UTTERANCE_ID, "MessageID") }
        tts.speak(text, TextToSpeech.QUEUE_FLUSH, params, "MessageID")
        addLog("ğŸ“¢ TTS: $text")
    }

    private fun processSelection(doc: DocumentSnapshot) {
        val hCode = doc.getString("householdCode") ?: "æœªçŸ¥"
        addLog("âœ… èªéŸ³é¸æ“‡: $hCode")
        speakOut("å¥½çš„ï¼Œç‚ºæ‚¨é¸æ“‡ $hCode")
    }

    private fun setupModernAudio() {
        val audioManager = getSystemService(AUDIO_SERVICE) as AudioManager
        audioManager.mode = AudioManager.MODE_IN_COMMUNICATION

        if (android.os.Build.VERSION.SDK_INT >= android.os.Build.VERSION_CODES.S) {
            val devices = audioManager.getDevices(AudioManager.GET_DEVICES_OUTPUTS)
            val btDevice = devices.find {
                it.type == AudioDeviceInfo.TYPE_BLUETOOTH_SCO ||
                        it.type == AudioDeviceInfo.TYPE_BLUETOOTH_A2DP
            }
            if (btDevice != null) {
                audioManager.setCommunicationDevice(btDevice)
                addLog("âœ… è—ç‰™é€šè¨Šé–å®š (S+)")
            }
        } else {
            @Suppress("DEPRECATION")
            audioManager.startBluetoothSco()
            @Suppress("DEPRECATION")
            audioManager.isBluetoothScoOn = true
            addLog("â„¹ï¸ å•Ÿå‹•èˆŠç‰ˆ SCO")
        }
    }

    private fun resetToNormalAudioMode() {
        val audioManager = getSystemService(AUDIO_SERVICE) as AudioManager
        audioManager.mode = AudioManager.MODE_NORMAL
        if (android.os.Build.VERSION.SDK_INT >= android.os.Build.VERSION_CODES.S) {
            audioManager.clearCommunicationDevice()
        }
        addLog("â™»ï¸ éŸ³è¨Šæ¨¡å¼å·²é‚„åŸ")
    }

    private fun stopSpeechLogic() {
        speechRecognizer.stopListening()
        tts.stop()
        isTtsSpeaking = false
    }

    private fun checkAudioSource(statusView: TextView) {
        val audioManager = getSystemService(AUDIO_SERVICE) as AudioManager
        val devices = audioManager.getDevices(AudioManager.GET_DEVICES_INPUTS)
        var sourceName = "æ‰‹æ©Ÿå…§å»ºéº¥å…‹é¢¨"
        for (device in devices) {
            if (device.type == AudioDeviceInfo.TYPE_BLUETOOTH_SCO) {
                sourceName = "JLab è—ç‰™è€³æ©Ÿ"
                break
            }
        }
        statusView.text = "æ”¶éŸ³è·¯å¾‘ï¼š$sourceName"
    }

    private fun convertSpokenPlate(text: String): String {
        var result = text
        val digitMap = mapOf(
            "é›¶" to "0", "ä¸€" to "1", "äºŒ" to "2", "ä¸‰" to "3", "å››" to "4",
            "äº”" to "5", "å…­" to "6", "ä¸ƒ" to "7", "å…«" to "8", "ä¹" to "9"
        )
        val regex = Regex("([0-9ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹])å€‹([0-9ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹é›¶])")
        val matches = regex.findAll(result)
        for (match in matches) {
            val count = digitMap[match.groupValues[1]]?.toIntOrNull() ?: match.groupValues[1].toIntOrNull() ?: 0
            val digit = digitMap[match.groupValues[2]] ?: match.groupValues[2]
            if (count > 0) result = result.replace(match.value, digit.repeat(count))
        }
        return result.replace(Regex("[^A-Za-z0-9]"), "").uppercase()
    }

    private fun setupFirestoreOffline() {
        val db = FirebaseFirestore.getInstance()
        val settings = FirebaseFirestoreSettings.Builder()
            .setLocalCacheSettings(PersistentCacheSettings.newBuilder()
                .setSizeBytes(100 * 1024 * 1024) // 100MB
                .build())
            .build()
        db.firestoreSettings = settings
        addLog("ğŸ“¦ [ä¿éšªç®±] å¼·åŒ–åˆå§‹åŒ–å®Œæˆ")
    }

    private fun syncAllDataForOffline(collectionPath: String) {
        val db = Firebase.firestore
        db.collection(collectionPath).get().addOnSuccessListener { documents ->
            addLog("ğŸ”„ $collectionPath åŒæ­¥å®Œæˆ (${documents.size()} ç­†)")
        }.addOnFailureListener {
            addLog("âŒ åŒæ­¥å¤±æ•—: ${it.message}")
        }
    }

    private fun addLog(text: String) {
        val time = SimpleDateFormat("HH:mm:ss", Locale.getDefault()).format(Date())
        runOnUiThread {
            tvDebugLog.append("\n[$time] $text")
            val scrollAmount = tvDebugLog.layout?.let {
                it.getLineTop(tvDebugLog.lineCount) - tvDebugLog.height
            } ?: 0
            if (scrollAmount > 0) tvDebugLog.scrollTo(0, scrollAmount)
        }
        Log.d("SmartGuard", "[$time] $text")
    }

    override fun onDestroy() {
        stopSpeechLogic()
        if (::tts.isInitialized) tts.shutdown()
        if (::speechRecognizer.isInitialized) speechRecognizer.destroy()
        super.onDestroy()
    }
}